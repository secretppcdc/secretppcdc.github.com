{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data files\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    file1 = open('training/news-commentary-v9.%s-%s.%s' % (lang1, lang2, lang1), mode = 'rb')\n",
    "    file2 = open('training/news-commentary-v9.%s-%s.%s' % (lang1, lang2, lang2), mode = 'rb')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    \n",
    "    line1 = file1.read().split(b'\\n')\n",
    "    line2 = file2.read().split(b'\\n')\n",
    "    #pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    pairs = []\n",
    "    \n",
    "    #print(len(line1))\n",
    "    #print(len(line2))\n",
    "    for i in range(len(line1)):\n",
    "        pairs.append([line1[i].decode('UTF8'),line2[i].decode('UTF8')])\n",
    "    \n",
    "    # Reverse pairs, make Lang instance    \n",
    "    \n",
    "    if reverse:\n",
    "        #pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "_,_,a=readLangs('fr','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tandis que le commerce bilatéral a augmenté, et que les relations diplomatiques se sont consolidées au cours des dernières années, une certaine ignorance persiste entre les deux régions et dans certains cas, les tensions s’intensifient.',\n",
       " 'While bilateral trade has increased and diplomatic relations have strengthened in the past few years, a lack of knowledge persists between the two regions, and in some cases tensions are growing.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1,lang2, part):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1,lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    #print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.2)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.shuffle(pairs)\n",
    "    test_pairs = pairs[num_test*(part-1):num_test*part]\n",
    "    set_test_eng = set([sent_eng for sent_eng, _ in test_pairs])\n",
    "    \n",
    "    test_pair_dict = {}\n",
    "    for sent_eng, sent_fre in pairs:\n",
    "        if sent_eng not in set_test_eng:\n",
    "            continue \n",
    "        elif sent_eng not in test_pair_dict:\n",
    "            test_pair_dict[sent_eng] = set([sent_fre])\n",
    "        else:\n",
    "            test_pair_dict[sent_eng].add(sent_fre)\n",
    "    test_pairs = [(sent_eng, list(test_pair_dict[sent_eng])) for sent_eng in test_pair_dict]\n",
    "    print(\"Number of test cases (sent + list):\", len(test_pairs))\n",
    "    \n",
    "    # collect train pairs\n",
    "    train_pairs = [(sent_eng, sent_fre) for sent_eng, sent_fre in (pairs[0:num_test*(part-1)]+pairs[num_test*part:]) if sent_eng not in set_test_eng]\n",
    "    print(\"Number of train pairs:\", len(train_pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in train_pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, train_pairs, test_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 183252 sentence pairs\n",
      "Number of test pairs: 31081\n",
      "Number of test cases (sent + list): 31024\n",
      "Number of train pairs: 124001\n",
      "Counting words...\n",
      "Reading lines...\n",
      "Read 183252 sentence pairs\n",
      "Number of test pairs: 31081\n",
      "Number of test cases (sent + list): 31020\n",
      "Number of train pairs: 124008\n",
      "Counting words...\n",
      "Reading lines...\n",
      "Read 183252 sentence pairs\n",
      "Number of test pairs: 31081\n",
      "Number of test cases (sent + list): 31028\n",
      "Number of train pairs: 123992\n",
      "Counting words...\n",
      "Reading lines...\n",
      "Read 183252 sentence pairs\n",
      "Number of test pairs: 31081\n",
      "Number of test cases (sent + list): 31003\n",
      "Number of train pairs: 124019\n",
      "Counting words...\n",
      "Reading lines...\n",
      "Read 183252 sentence pairs\n",
      "Number of test pairs: 31081\n",
      "Number of test cases (sent + list): 31024\n",
      "Number of train pairs: 124010\n",
      "Counting words...\n"
     ]
    }
   ],
   "source": [
    "input_lang_fr_en1, output_lang_fr_en1,train_pairs_fr_en1, test_pairs_fr_en1 = prepareData('fr','en',1)\n",
    "input_lang_fr_en2, output_lang_fr_en2,train_pairs_fr_en2, test_pairs_fr_en2 = prepareData('fr','en',2)\n",
    "input_lang_fr_en3, output_lang_fr_en3,train_pairs_fr_en3, test_pairs_fr_en3 = prepareData('fr','en',3)\n",
    "input_lang_fr_en4, output_lang_fr_en4,train_pairs_fr_en4, test_pairs_fr_en4 = prepareData('fr','en',4)\n",
    "input_lang_fr_en5, output_lang_fr_en5,train_pairs_fr_en5, test_pairs_fr_en5 = prepareData('fr','en',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ils reviendront en Russie (attirés aussi par des salaires élevés) pour se rendre célèbre et faire la fierté de leur mère patrie.', ['They will come back to Russia (also drawn by high salaries) to make themselves famous and their motherland proud.'])\n"
     ]
    }
   ],
   "source": [
    "print(test_pairs_fr_en1[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 165603 sentence pairs\n",
      "Number of test pairs: 27805\n",
      "Number of test cases (sent + list): 27773\n",
      "Number of train pairs: 110985\n",
      "Counting words...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_lang_ru_en1, output_lang_ru_en1,train_pairs_ru_en1, test_pairs_ru_en1 = prepareData('ru','en',1)\n",
    "#input_lang_ru_en2, output_lang_ru_en2,train_pairs_ru_en2, test_pairs_ru_en2 = prepareData('ru','en',2)\n",
    "#input_lang_ru_en3, output_lang_ru_en3,train_pairs_ru_en3, test_pairs_ru_en3 = prepareData('ru','en',3)\n",
    "#input_lang_ru_en4, output_lang_ru_en4,train_pairs_ru_en4, test_pairs_ru_en4 = prepareData('ru','en',4)\n",
    "#input_lang_ru_en5, output_lang_ru_en5,train_pairs_ru_en5, test_pairs_ru_en5 = prepareData('ru','en',5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Но формула роста, на которую долгое время опирался экономический успех Южной Кореи – разновидность государственного капитализма, основанного на экспортно-ориентированном производстве – больше не работает для многих корейцев.', 'But the growth formula that long underpinned South Korea’s success – a form of state-guided capitalism that focuses on export-led manufacturing – is no longer working for many South Koreans.')\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(train_pairs_ru_en1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 146550 sentence pairs\n",
      "Number of test pairs: 27269\n",
      "Number of test cases (sent + list): 27217\n",
      "Number of train pairs: 108767\n",
      "Counting words...\n",
      "('V tomto směru je výkon Evropy systematicky nižší než výkon USA: v průměru o 30 %, podle jednotlivých zemí pak například v Británii o 43 % a v Německu o 56 %.', \"Here Europe's performance is consistently below that of America: 30% on average, with the U.K. 43% and Germany 56% below the US.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_lang_cs_en1, output_lang_cs_en1,train_pairs_cs_en1, test_pairs_cs_en1 = prepareData('cs','en',1)\n",
    "#input_lang_cs_en2, output_lang_cs_en2,train_pairs_cs_en2, test_pairs_cs_en2 = prepareData('cs','en',2)\n",
    "#input_lang_cs_en3, output_lang_cs_en3,train_pairs_cs_en3, test_pairs_cs_en3 = prepareData('cs','en',3)\n",
    "#input_lang_cs_en4, output_lang_cs_en4,train_pairs_cs_en4, test_pairs_cs_en4 = prepareData('cs','en',4)\n",
    "#input_lang_cs_en5, output_lang_cs_en5,train_pairs_cs_en5, test_pairs_cs_en5 = prepareData('cs','en',5)\n",
    "print(random.choice(train_pairs_cs_en1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 201289 sentence pairs\n",
      "Number of test pairs: 36365\n",
      "Number of test cases (sent + list): 36258\n",
      "Number of train pairs: 145033\n",
      "Counting words...\n",
      "('Mehr noch: Die meisten entdecken, dass, wenn sich die Versammlung tatsächlich einmal mit konkreten Vorschlägen befasst – was selten vorkommt –, diese Vorschläge nicht nach ihrem Geschmack sind.', 'Moreover, most find that when the Assembly gets to deal with specific proposals, which is rare, the proposals are disagreeable.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_lang_de_en1, output_lang_de_en1,train_pairs_de_en1, test_pairs_de_en1 = prepareData('de','en',1)\n",
    "#input_lang_de_en2, output_lang_de_en2,train_pairs_de_en2, test_pairs_de_en2 = prepareData('de','en',2)\n",
    "#input_lang_de_en3, output_lang_de_en3,train_pairs_de_en3, test_pairs_de_en3 = prepareData('de','en',3)\n",
    "#input_lang_de_en4, output_lang_de_en4,train_pairs_de_en4, test_pairs_de_en4 = prepareData('de','en',4)\n",
    "#input_lang_de_en5, output_lang_de_en5,train_pairs_de_en5, test_pairs_de_en5 = prepareData('de','en',5)\n",
    "print(random.choice(train_pairs_de_en1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(random.choice(train_pairs_de_en2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seq2Seq Model\n",
    "================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention in Turorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_lecture(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_lecture, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        output = embedded\n",
    "        output, hidden2 = self.gru(output, hidden)\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0]),1)), dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((output[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicative attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_mul(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_mul, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.mul = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden2 = self.gru(embedded, hidden)\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((self.mul(output[0]), hidden[0]), 1)), dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((output[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_add(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_add, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.w1 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.w2 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.w3 = nn.Linear(self.hidden_size,self.max_length)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden2 = self.gru(embedded, hidden)\n",
    "        \n",
    "        attn_weights = F.softmax(self.w3(torch.tanh(self.w1(output[0])+ self.w2(hidden[0]))), dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((output[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(input_lang,output_lang,pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(input_lang,output_lang,train_pairs, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.02):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(input_lang,output_lang,random.choice(train_pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_lang,output_lang,encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def eval_changenorm(self, alpha=1.0):\n",
    "        reward = 0\n",
    "\n",
    "        return self.logp / float(np.sqrt(self.leng) - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(input_lang,output_lang,encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluate_beam_search_changenorm(input_lang,output_lang,encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval_changenorm(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval_changenorm()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluate_beam_search_changelength(input_lang,output_lang,encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 3000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(input_lang, output_lang,encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(input_lang, output_lang,encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(input_lang, output_lang,encoder, decoder, pairs):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate(input_lang, output_lang,encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(input_lang, output_lang, encoder, decoder, beam_size, pairs):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate_beam_search(input_lang, output_lang,encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluateBleu_beam_search_changenorm(input_lang, output_lang, encoder, decoder, beam_size, pairs):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate_beam_search_changenorm(input_lang, output_lang,encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluateBleu_beam_search_changelength(input_lang, output_lang, encoder, decoder, beam_size, pairs):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate_beam_search_changelength(input_lang, output_lang,encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluating\n",
    "======================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## french_english evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 53s (- 17m 47s) (5000 33%) 6.5990\n",
      "18m 6s (- 9m 3s) (10000 66%) 6.3757\n",
      "27m 14s (- 0m 0s) (15000 100%) 6.2638\n",
      "0.001984157908722032\n",
      "0.001984157908722032\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder_fr_en1 = EncoderRNN(input_lang_fr_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en1 = AttnDecoderRNN(hidden_size, output_lang_fr_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_fr_en2 = EncoderRNN(input_lang_fr_en2.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en2 = AttnDecoderRNN(hidden_size, output_lang_fr_en2.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_fr_en3 = EncoderRNN(input_lang_fr_en3.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en3 = AttnDecoderRNN(hidden_size, output_lang_fr_en3.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_fr_en4 = EncoderRNN(input_lang_fr_en4.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en4 = AttnDecoderRNN(hidden_size, output_lang_fr_en4.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_fr_en5 = EncoderRNN(input_lang_fr_en5.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en5 = AttnDecoderRNN(hidden_size, output_lang_fr_en5.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_fr_en1,output_lang_fr_en1, train_pairs_fr_en1, encoder_fr_en1, attn_decoder_fr_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "print(score11)\n",
    "#score11 = evaluateBleu_beam_search(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1,10, test_pairs_fr_en1)\n",
    "print(score11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 49s (- 17m 39s) (5000 33%) 6.6270\n",
      "18m 11s (- 9m 5s) (10000 66%) 6.5067\n",
      "27m 27s (- 0m 0s) (15000 100%) 6.3153\n",
      "8m 55s (- 17m 51s) (5000 33%) 6.7682\n",
      "17m 59s (- 8m 59s) (10000 66%) 6.4457\n",
      "27m 11s (- 0m 0s) (15000 100%) 6.2879\n",
      "9m 3s (- 18m 7s) (5000 33%) 6.6314\n",
      "18m 10s (- 9m 5s) (10000 66%) 6.4738\n",
      "27m 30s (- 0m 0s) (15000 100%) 6.3483\n",
      "8m 52s (- 17m 44s) (5000 33%) 6.5984\n",
      "18m 0s (- 9m 0s) (10000 66%) 6.4906\n",
      "27m 16s (- 0m 0s) (15000 100%) 6.3664\n",
      "avg BLEU score(fr-en) avg0.009865307610083805\n",
      "avg BLEU score with beam search(fr-en)0.0021557481649198073\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluateBleu_beam_search_changenorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-c28980947e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mscore12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluateBleu_beam_search_changenorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_lang_fr_en1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_lang_fr_en1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_fr_en1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_decoder_fr_en1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pairs_fr_en1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mscore_fr_en_beam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'avg BLEU score with beam search change norm(fr-en)'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_fr_en_beam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluateBleu_beam_search_changenorm' is not defined"
     ]
    }
   ],
   "source": [
    "trainIters(input_lang_fr_en2,output_lang_fr_en2,train_pairs_fr_en2, encoder_fr_en2, attn_decoder_fr_en2, 15000, print_every=5000)\n",
    "trainIters(input_lang_fr_en3,output_lang_fr_en3,train_pairs_fr_en3, encoder_fr_en3, attn_decoder_fr_en3, 15000, print_every=5000)\n",
    "trainIters(input_lang_fr_en4,output_lang_fr_en4,train_pairs_fr_en4, encoder_fr_en4, attn_decoder_fr_en4, 15000, print_every=5000)\n",
    "trainIters(input_lang_fr_en5,output_lang_fr_en5,train_pairs_fr_en5, encoder_fr_en5, attn_decoder_fr_en5, 15000, print_every=5000)\n",
    "\n",
    "#score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "score12 = evaluateBleu(input_lang_fr_en2,output_lang_fr_en2,encoder_fr_en2, attn_decoder_fr_en2, test_pairs_fr_en2)\n",
    "score13 = evaluateBleu(input_lang_fr_en3,output_lang_fr_en3,encoder_fr_en3, attn_decoder_fr_en3, test_pairs_fr_en3)\n",
    "score14 = evaluateBleu(input_lang_fr_en4,output_lang_fr_en4,encoder_fr_en4, attn_decoder_fr_en4, test_pairs_fr_en4)\n",
    "score15 = evaluateBleu(input_lang_fr_en5,output_lang_fr_en5,encoder_fr_en5, attn_decoder_fr_en5, test_pairs_fr_en5)\n",
    "\n",
    "score_fr_en = score11+score12+score13+score14+score15\n",
    "print('avg BLEU score(fr-en) avg'+ str(score_fr_en))\n",
    "\n",
    "score12 = evaluateBleu_beam_search(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1,2, test_pairs_fr_en1)\n",
    "score_fr_en_beam = score12\n",
    "print('avg BLEU score with beam search(fr-en)'+ str(score_fr_en_beam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score12 = evaluateBleu_beam_search_changenorm(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1,2, test_pairs_fr_en1)\n",
    "score_fr_en_beam = score12\n",
    "print('avg BLEU score with beam search change norm(fr-en)'+ str(score_fr_en_beam))\n",
    "\n",
    "score13 = evaluateBleu_beam_search_changelength(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1,2, test_pairs_fr_en1)\n",
    "score_fr_en_beam = score13\n",
    "print('avg BLEU score with beam search change length(fr-en)'+ str(score_fr_en_beam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czech-English Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 22s (- 18m 45s) (5000 33%) 6.5626\n",
      "19m 11s (- 9m 35s) (10000 66%) 6.5008\n",
      "28m 58s (- 0m 0s) (15000 100%) 6.3724\n",
      "avg BLEU score(cs-en)0.0015344943690661673\n",
      "avg BLEU score with beam search(cs-en)0.002016930280540274\n"
     ]
    }
   ],
   "source": [
    "encoder_cs_en1 = EncoderRNN(input_lang_cs_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_cs_en1 = AttnDecoderRNN(hidden_size, output_lang_cs_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_cs_en1,output_lang_cs_en1,train_pairs_cs_en1, encoder_cs_en1, attn_decoder_cs_en1, 15000, print_every=5000)\n",
    "\n",
    "score14 = evaluateBleu(input_lang_cs_en1,output_lang_cs_en1,encoder_cs_en1, attn_decoder_cs_en1, test_pairs_cs_en1)\n",
    "score_cs_en = score14\n",
    "print('avg BLEU score(cs-en)'+ str(score_cs_en))\n",
    "\n",
    "score15 = evaluateBleu_beam_search(input_lang_cs_en1,output_lang_cs_en1,encoder_cs_en1, attn_decoder_cs_en1,2, test_pairs_cs_en1)\n",
    "score_cs_en_beam = score15\n",
    "print('avg BLEU score with beam search(cs-en)'+ str(score_cs_en_beam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian-English Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21m 29s (- 42m 58s) (5000 33%) 6.4440\n",
      "43m 58s (- 21m 59s) (10000 66%) 6.4212\n",
      "66m 34s (- 0m 0s) (15000 100%) 6.2962\n",
      "avg BLEU score(ru-en)0.001300824132319994\n",
      "avg BLEU score with beam search(ru-en)0.0017648643208576394\n"
     ]
    }
   ],
   "source": [
    "encoder_ru_en1 = EncoderRNN(input_lang_ru_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_ru_en1 = AttnDecoderRNN(hidden_size, output_lang_ru_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_ru_en1,output_lang_ru_en1,train_pairs_ru_en1, encoder_ru_en1, attn_decoder_ru_en1, 15000, print_every=5000)\n",
    "\n",
    "score16 = evaluateBleu(input_lang_ru_en1,output_lang_ru_en1,encoder_ru_en1, attn_decoder_ru_en1, test_pairs_ru_en1)\n",
    "score_ru_en = score16\n",
    "print('avg BLEU score(ru-en)'+ str(score_ru_en))\n",
    "\n",
    "score17 = evaluateBleu_beam_search(input_lang_ru_en1,output_lang_ru_en1,encoder_ru_en1, attn_decoder_ru_en1,2, test_pairs_ru_en1)\n",
    "score_ru_en_beam = score17\n",
    "print('avg BLEU score with beam search(ru-en)'+ str(score_ru_en_beam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German-English Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_de_en1 = EncoderRNN(input_lang_de_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_de_en1 = AttnDecoderRNN(hidden_size, output_lang_de_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_de_en1,output_lang_de_en1,train_pairs_de_en1, encoder_de_en1, attn_decoder_de_en1, 15000, print_every=5000)\n",
    "\n",
    "score18 = evaluateBleu(input_lang_de_en1,output_lang_de_en1,encoder_de_en1, attn_decoder_de_en1, test_pairs_de_en1)\n",
    "score_de_en = score18\n",
    "print('avg BLEU score(de-en)'+ str(score_de_en))\n",
    "\n",
    "score19 = evaluateBleu_beam_search(input_lang_de_en1,output_lang_de_en1,encoder_de_en1, attn_decoder_de_en1,2, test_pairs_de_en1)\n",
    "score_de_en_beam = score19\n",
    "print('avg BLEU score with beam search(de-en)'+ str(score_de_en_beam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention in tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder_fr_en1 = EncoderRNN(input_lang_fr_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en1 = AttnDecoderRNN(hidden_size, output_lang_fr_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_fr_en1,output_lang_fr_en1,train_pairs_fr_en1, encoder_fr_en1, attn_decoder_fr_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "\n",
    "print(' BLEU score for attention in tutorial(fr-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention in lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fr_en1 = EncoderRNN(input_lang_fr_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en1 = AttnDecoderRNN_lecture(hidden_size, output_lang_fr_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_fr_en1,output_lang_fr_en1,train_pairs_fr_en1, encoder_fr_en1, attn_decoder_fr_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "\n",
    "print(' BLEU score for attention in lecture(fr-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cs_en1 = EncoderRNN(input_lang_cs_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_cs_en1 = AttnDecoderRNN_lecture(hidden_size, output_lang_cs_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_cs_en1,output_lang_cs_en1,train_pairs_cs_en1, encoder_cs_en1, attn_decoder_cs_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_cs_en1,output_lang_cs_en1,encoder_cs_en1, attn_decoder_cs_en1, test_pairs_cs_en1)\n",
    "\n",
    "print(' BLEU score for attention in lecture(cs-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_ru_en1 = EncoderRNN(input_lang_ru_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_ru_en1 = AttnDecoderRNN_lecture(hidden_size, output_lang_ru_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_ru_en1,output_lang_ru_en1,train_pairs_ru_en1, encoder_ru_en1, attn_decoder_ru_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_ru_en1,output_lang_ru_en1,encoder_ru_en1, attn_decoder_ru_en1, test_pairs_ru_en1)\n",
    "\n",
    "print(' BLEU score for attention in lecture(ru-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_de_en1 = EncoderRNN(input_lang_de_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_de_en1 = AttnDecoderRNN_lecture(hidden_size, output_lang_de_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_de_en1,output_lang_de_en1,train_pairs_de_en1, encoder_de_en1, attn_decoder_de_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_de_en1,output_lang_de_en1,encoder_de_en1, attn_decoder_de_en1, test_pairs_de_en1)\n",
    "\n",
    "print(' BLEU score for attention in lecture(de-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicative attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fr_en1 = EncoderRNN(input_lang_fr_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en1 = AttnDecoderRNN_mul(hidden_size, output_lang_fr_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_fr_en1,output_lang_fr_en1,train_pairs_fr_en1, encoder_fr_en1, attn_decoder_fr_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "\n",
    "print(' BLEU score for Multiplicative attention(fr-en)')\n",
    "print(score11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fr_en1 = EncoderRNN(input_lang_fr_en1.n_words, hidden_size).to(device)\n",
    "attn_decoder_fr_en1 = AttnDecoderRNN_add(hidden_size, output_lang_fr_en1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(input_lang_fr_en1,output_lang_fr_en1,train_pairs_fr_en1, encoder_fr_en1, attn_decoder_fr_en1, 15000, print_every=5000)\n",
    "\n",
    "score11 = evaluateBleu(input_lang_fr_en1,output_lang_fr_en1,encoder_fr_en1, attn_decoder_fr_en1, test_pairs_fr_en1)\n",
    "\n",
    "print(' BLEU score for Additive attention attention(fr-en)')\n",
    "print(score11)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
